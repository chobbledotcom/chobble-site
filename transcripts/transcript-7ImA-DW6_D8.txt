Title: Tracking search results with SerpBear & ScrapingRobot, hosted on Pikapods
Video ID: 7ImA-DW6_D8
Channel: Chobble

---

[0:00 - 0:04] from patreon.com/trouble
[0:04 - 0:07] Tracking search positions
[0:07 - 0:08] I thought what could be interesting
[0:08 - 0:09] today could be to show you how I track
[0:09 - 0:13] the search results of various websites
[0:13 - 0:14] There's lots of reasons why you might be
[0:14 - 0:16] interested in the search results of a
[0:16 - 0:17] website For example you might be trying
[0:17 - 0:19] to improve it and you might want the
[0:19 - 0:20] site to rank better than it currently
[0:20 - 0:23] does And in order to know how much
[0:23 - 0:25] you're progressing you have to be able
[0:25 - 0:28] to track that month over month
[0:28 - 0:32] You could just visit Google yourself
[0:32 - 0:35] regularly and note down in a notepad
[0:35 - 0:38] what position your site was showing on
[0:38 - 0:40] but that I think is very crude
[0:40 - 0:42] Your position changes quite a lot kind
[0:42 - 0:44] of dayto-day And there's a lot of
[0:44 - 0:47] variables that go into which order
[0:47 - 0:48] Google displays websites in for each
[0:48 - 0:51] visitor And it's hard for you to rule
[0:51 - 0:52] all those variables out especially if
[0:52 - 0:54] you're doing this consistently I find it
[0:54 - 0:55] really useful to use a search engine
[0:55 - 0:58] results tracker And that way you can see
[0:58 - 1:00] week by week month by month how your
[1:00 - 1:02] website is doing in search engines The
[1:02 - 1:04] one that I'm using here is called SER
[1:04 - 1:07] Bear S E R P Bear And it's free and open
[1:07 - 1:09] source software which means that if you
[1:09 - 1:10] can get your head around the technical
[1:10 - 1:12] aspects of setting it up you can track
[1:12 - 1:14] quite a lot of search results through
[1:14 - 1:15] this without it costing you anything
[1:15 - 1:18] We're going to combine SER Bear with
[1:18 - 1:20] Scraping Robot There's two aspects to
[1:20 - 1:22] determining where you are in search
[1:22 - 1:24] results The first step is actually to
[1:24 - 1:26] read the search results The second step
[1:26 - 1:28] is to store those results and organize
[1:28 - 1:30] them over a timeline So for the first
[1:30 - 1:32] step that's kind of a specialist
[1:32 - 1:35] industry now of scraping websites
[1:35 - 1:37] because Google don't really want you to
[1:37 - 1:39] scrape search results So they make it
[1:39 - 1:41] difficult So businesses have popped up
[1:41 - 1:44] like scraping robot that specialize in
[1:44 - 1:46] scraping websites even though Google
[1:46 - 1:49] might not really want you to scrape it
[1:49 - 1:51] To scrape I should clarify means
[1:51 - 1:52] basically to just download the
[1:52 - 1:55] information of it in some way that an
[1:55 - 1:58] algorithm or a computer program can pass
[1:58 - 1:59] So forgive me for getting a bit
[1:59 - 2:00] technical there but basically we're
[2:00 - 2:02] going to sign up for scraping robot and
[2:02 - 2:04] then we're going to put the details of
[2:04 - 2:07] that into our SER bear setup I'm going
[2:07 - 2:09] to show you how to set up SER Bear as
[2:09 - 2:12] well And then you'll have a system there
[2:12 - 2:14] that you can log into that longterm you
[2:14 - 2:16] can use to track how your site is doing
[2:16 - 2:17] in search results There's nothing in
[2:17 - 2:19] here that's actually complicated I will
[2:19 - 2:21] be talking about technical stuff but if
[2:21 - 2:23] you follow my instructions there's not
[2:23 - 2:24] any reason why you shouldn't be able to
[2:24 - 2:26] do it So the first step is to visit
[2:26 - 2:28] papods.com
[2:28 - 2:30] p ikapods.com
[2:30 - 2:34] p i k a p o ds.com Peekapods is a
[2:34 - 2:36] website that lets you host open-source
[2:36 - 2:39] web apps yourself So an open- source web
[2:39 - 2:43] app to clarify that means a website
[2:43 - 2:45] platform where the people who've made it
[2:45 - 2:47] have released the source code for anyone
[2:47 - 2:50] to read and use as they see fit This is
[2:50 - 2:52] an excellent model I think it means that
[2:52 - 2:53] the community and the wider internet can
[2:53 - 2:55] benefit from these apps without them
[2:55 - 2:57] being locked down to some proprietary
[2:57 - 3:00] company or hidden behind a payw wall or
[3:00 - 3:03] anything like that And what Popods do is
[3:03 - 3:06] let you really easily run a whole bunch
[3:06 - 3:08] of open-source web apps There's all
[3:08 - 3:10] sorts of interesting stuff in here I've
[3:10 - 3:12] used it for hosting websites for
[3:12 - 3:14] managing newsletters for tracking the
[3:14 - 3:16] uptime of my other sites for all sorts
[3:16 - 3:19] of stuff It's super cool But for now
[3:19 - 3:21] we're just going to get into SER Bear
[3:21 - 3:23] specifically So you'll want to visit
[3:23 - 3:26] papods.com and sign up I'm not going to
[3:26 - 3:27] walk through the sign up process It's
[3:27 - 3:29] exactly as you'd expect You put your
[3:29 - 3:30] email address in you choose a password
[3:30 - 3:32] then you're logged in You're going to
[3:32 - 3:33] have to add some credit to your account
[3:33 - 3:36] because hosting a web app isn't free as
[3:36 - 3:38] in it uses some amount of server
[3:38 - 3:39] resources So that's what you're going to
[3:39 - 3:41] pay for through Pika Pods But it'll be
[3:41 - 3:43] really cheap to host Ser Bear You're
[3:43 - 3:45] probably looking at one or two pound a
[3:45 - 3:47] month total And that's way cheaper than
[3:47 - 3:49] the next cheapest option that you're
[3:49 - 3:50] going to find in terms of tracking
[3:50 - 3:52] search results If you felt particularly
[3:52 - 3:55] kind of brave you could try hosting this
[3:55 - 3:58] at home on your own machine on your
[3:58 - 3:59] laptop even and then you wouldn't even
[3:59 - 4:01] need to pay for hosting But that's
[4:01 - 4:02] probably a little bit too technical to
[4:02 - 4:04] get into in a video Peekapods makes it
[4:04 - 4:06] really easy Okay again forgive me for
[4:06 - 4:08] waffling but we go to Peekabods You're
[4:08 - 4:10] signed up you click view available apps
[4:10 - 4:12] and then in the top right find apps
[4:12 - 4:15] You're going to type SER s and you'll
[4:15 - 4:17] see SER bear comes up and it says here
[4:17 - 4:19] it's going to cost from $150 a month to
[4:19 - 4:22] run Click run your own and then it's
[4:22 - 4:24] going to ask you for some details for
[4:24 - 4:26] this pod The defaults here are probably
[4:26 - 4:28] fine But one thing that you are going to
[4:28 - 4:30] need to do is set a password So if you
[4:30 - 4:32] go to the end vase which means
[4:32 - 4:35] environmental variables that tab and
[4:35 - 4:36] then you'll see there's user and
[4:36 - 4:38] password and API key You can actually
[4:38 - 4:40] put whatever you like in the API key
[4:40 - 4:42] because it's not going to be used But
[4:42 - 4:44] the username we'll put Stefan and the
[4:44 - 4:46] password we'll put password You'll put a
[4:46 - 4:48] proper proper password and the API key
[4:48 - 4:50] will put some gobbledygook because we're
[4:50 - 4:51] not actually going to use it And then
[4:51 - 4:53] click add pod Easy peasy This takes a
[4:53 - 4:55] second while picapods in the background
[4:55 - 4:57] deploy this app So that means that they
[4:57 - 4:59] get some of their server resources They
[4:59 - 5:02] cordon it off to one side and they
[5:02 - 5:04] install this app that you've just chosen
[5:04 - 5:05] on it And you can see here now it's
[5:05 - 5:07] popped up and it's given us the domain
[5:07 - 5:10] name lovely kagu.picapod.net
[5:10 - 5:12] And if I click that you'll see it loads
[5:12 - 5:15] me straight into the serar login page
[5:15 - 5:16] and I can loging in with that username
[5:16 - 5:18] and password that I just made and you'll
[5:18 - 5:19] see that I'm logged into there So just
[5:19 - 5:21] like that in what was that maybe a
[5:21 - 5:23] couple of minutes we've set up a totally
[5:23 - 5:25] fresh web app and we've logged into it
[5:25 - 5:27] and now we're ready to connect this to
[5:27 - 5:28] scraping robot So what you're going to
[5:28 - 5:30] do next is go to scrapingroot.com and
[5:30 - 5:32] sign up for this Again this is really
[5:32 - 5:34] easy Click the sign up button You fill
[5:34 - 5:36] in the registration details name last
[5:36 - 5:38] name email address and you choose a
[5:38 - 5:39] password for this Hopefully you're using
[5:39 - 5:41] a password manager like I've mentioned
[5:41 - 5:43] before Click to verify that you're over
[5:43 - 5:44] 18 years old and that you agree to the
[5:44 - 5:46] terms and conditions which you should
[5:46 - 5:48] definitely read in full And then you
[5:48 - 5:49] click to confirm that you're not a robot
[5:49 - 5:51] and click get started You'll see here
[5:51 - 5:54] that you get 5,000 free scrapes every
[5:54 - 5:56] month That means that your SER be there
[5:56 - 5:59] setup can trigger 5,000 scrapes from
[5:59 - 6:01] scraping robot every month It's kind of
[6:01 - 6:03] complicated to work out the maths of how
[6:03 - 6:05] many search results specifically this is
[6:05 - 6:06] going to get you to track but in my
[6:06 - 6:10] experience 5,000 will do loads It'll
[6:10 - 6:12] definitely do at least one business You
[6:12 - 6:13] probably only want to check the search
[6:13 - 6:14] results every day but you could drop
[6:14 - 6:16] that down to every couple of days and
[6:16 - 6:18] that would still probably be fine So
[6:18 - 6:19] once you're signed into Scraping Robot
[6:19 - 6:20] really straightforward You're going to
[6:20 - 6:23] click the API info link on the left and
[6:23 - 6:25] it gives you this API key This is all
[6:25 - 6:26] you need from scraping robot So you're
[6:26 - 6:28] going to copy this Then you go back to
[6:28 - 6:30] SER Bear click the settings icon up at
[6:30 - 6:32] the top change your scraping method to
[6:32 - 6:34] scraping robot and paste the API key in
[6:34 - 6:36] the box below And you see here it's
[6:36 - 6:38] talking about the scraping frequency
[6:38 - 6:40] Daily every other day weekly monthly or
[6:40 - 6:42] never I'd say every other day is
[6:42 - 6:43] probably plenty Or you can leave it on
[6:43 - 6:44] daily You probably only need to change
[6:44 - 6:46] this to weekly or monthly if you're
[6:46 - 6:48] adding lots and lots and lots of
[6:48 - 6:49] keywords in And then you'll see there's
[6:49 - 6:51] a tick box on here Auto retry failed
[6:51 - 6:54] keyword scrape Sometimes scraping robot
[6:54 - 6:55] won't be able to scrape a keyword for
[6:55 - 6:56] whatever reason It doesn't really give
[6:56 - 6:59] you the details If you click this auto
[6:59 - 7:02] retry box it'll retry when that happens
[7:02 - 7:04] So you filled in your URLs you press
[7:04 - 7:06] update settings Settings are updated And
[7:06 - 7:07] now we're ready to start using search
[7:07 - 7:09] bear So this is really straightforward
[7:09 - 7:11] You click to add a domain You paste your
[7:11 - 7:13] website early in So I'll put chubble.com
[7:13 - 7:14] And then you'll see that it's made a
[7:14 - 7:16] page for chubble.com You've got add
[7:16 - 7:18] keywords in the top And then you need to
[7:18 - 7:20] filter this down to United Kingdom
[7:20 - 7:22] because otherwise it'll be searching for
[7:22 - 7:24] the USA by default And I'm going to
[7:24 - 7:26] search for web design press switch which
[7:26 - 7:28] hopefully I'll be ranking somewhere for
[7:28 - 7:30] And then we click add keywords And
[7:30 - 7:32] you'll see it starts spinning That means
[7:32 - 7:33] that scraping robot in the background is
[7:33 - 7:35] looking for the position for this and
[7:35 - 7:37] it's spun around and then you'll see
[7:37 - 7:39] that it's got us ranking for position 20
[7:39 - 7:41] for web design press which this isn't
[7:41 - 7:43] great but hopefully it'll get better
[7:43 - 7:44] Then you can click on this keyword and
[7:44 - 7:46] you can see the history of it over time
[7:46 - 7:47] and you can see the full details of who
[7:47 - 7:52] was ranking for that term my competition
[7:52 - 7:53] So here you can add a whole bunch of
[7:53 - 7:55] keywords and then search bear in the
[7:55 - 7:57] background will scrape that keyword at
[7:57 - 7:59] the frequency that you've set up and
[7:59 - 8:01] then you can track your results here
[8:01 - 8:03] over time What you'll probably find and
[8:03 - 8:05] this is what definitely what I find is
[8:05 - 8:06] that the search results kind of jump
[8:06 - 8:08] around all over the place without too
[8:08 - 8:11] much rhyme or reason So really I find it
[8:11 - 8:14] much more useful to track a long-term
[8:14 - 8:16] trend for a keyword rather than worrying
[8:16 - 8:18] about the day-to-day fluctuations in
[8:18 - 8:20] rankings for a specific keyword Like
[8:20 - 8:22] everything in SEO and search engines
[8:22 - 8:24] we're playing the long game here It's
[8:24 - 8:27] about establishing long-term trends and
[8:27 - 8:30] looking for long-term increases in your
[8:30 - 8:32] positions If you get S Bear set up and
[8:32 - 8:34] you find out that your search engine
[8:34 - 8:37] rankings seem to be dropping one day and
[8:37 - 8:38] then maybe they go up two spots the next
[8:38 - 8:40] day and then they go down one the day
[8:40 - 8:42] after that don't fret too much about it
[8:42 - 8:44] There's a degree of randomness to these
[8:44 - 8:46] search results that is inescapable The
[8:46 - 8:48] aim here is to track your long-term
[8:48 - 8:51] trends I find SER Bear can be really
[8:51 - 8:53] useful if you're just about to make a
[8:53 - 8:54] change on your site and you're not 100%
[8:54 - 8:56] sure about whether this is going to have
[8:56 - 8:58] a beneficial impact or not Tracking the
[8:58 - 9:00] keywords on SER Bear will let you see
[9:00 - 9:02] how Google actually reacts to those
[9:02 - 9:04] changes And I found that generally
[9:04 - 9:06] things work well You know if you make a
[9:06 - 9:08] page on your website much better you
[9:08 - 9:10] will find that its rankings do go up
[9:10 - 9:12] There's a few days lag on all of this
[9:12 - 9:13] You know Google needs to find out about
[9:13 - 9:15] the new changes They need to index your
[9:15 - 9:17] site They need to update their index to
[9:17 - 9:20] suit But I do find that you by using
[9:20 - 9:22] Bear I'm able to see oh yeah that
[9:22 - 9:24] keyword has got better because I
[9:24 - 9:26] improved those pages that were related
[9:26 - 9:28] to it Okay there's a lot more to bear
[9:28 - 9:30] here We can also connect it to Google
[9:30 - 9:32] Ads and you can connect it to your
[9:32 - 9:34] Google search console to bring in data
[9:34 - 9:35] from that But for now I think I've given
[9:35 - 9:37] you quite enough to get on with here
[9:37 - 9:39] with signing up for Peekapods signing up
[9:39 - 9:43] for scraping robot getting that API key
[9:43 - 9:46] copying it into your SER bear setup on
[9:46 - 9:48] Pika Pods and then adding your first
[9:48 - 9:50] website and keywords and tracking those
[9:50 - 9:51] If you have any problems with any of
[9:51 - 9:53] this please do let me know And if you
[9:53 - 9:55] successfully get it set up please let me
[9:55 - 9:56] know about that as well I'd be really
[9:56 - 9:58] keen to hear about anyone who gets this
[9:58 - 10:00] working Hopefully you haven't found any
[10:00 - 10:02] of it too complicated Like I said we
[10:02 - 10:03] didn't really have to get into anything
[10:03 - 10:05] particularly technical there but I know
[10:05 - 10:07] that it can feel kind of overwhelming to
[10:07 - 10:10] do things like copying an API key or
[10:10 - 10:11] setting up a new domain name things like
[10:11 - 10:13] that It can feel more overwhelming than
[10:13 - 10:15] it really is once you get stuck into it
[10:15 - 10:17] Okay as ever hope this was useful Any
[10:17 - 10:19] ideas for future videos please let me
[10:19 - 10:23] know Thanks for listening Over and out
